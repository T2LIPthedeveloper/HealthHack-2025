{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pill Type Classification using TensorFlow\n",
    "\n",
    "This notebook builds a robust TensorFlow classification model for the OGYEIv2 pill dataset from Kaggle. It includes a strong data pipeline using `tf.data.Dataset` for augmentation, evaluation with F1 score, backtesting, and conversion to TensorFlow Lite for deployment.\n",
    "\n",
    "Supreme Leader, ensure you have downloaded the dataset from Kaggle and placed it in the `./data/ogyeiv2` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# For evaluation metrics\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Place the downloaded OGYEIv2 dataset in the `./data/ogyeiv2` folder. The folder structure should be organized by class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset path and parameters\n",
    "data_dir = os.path.join(os.getcwd(), 'data', '')\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "# Load training and validation datasets using an 80-20 split\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Optimize dataset performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print('Datasets prepared.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Data augmentation improves model generalization by applying random transformations to the training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.RandomRotation(0.1),\n",
    "  tf.keras.layers.RandomZoom(0.1)\n",
    "])\n",
    "\n",
    "# Visualize some augmented images (optional)\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    augmented_images = data_augmentation(images)\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[i].numpy().astype('uint8'))\n",
    "        plt.axis('off')\n",
    "    break\n",
    "plt.show()\n",
    "\n",
    "print('Data augmentation pipeline created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "We define a CNN model using the Keras API. Data augmentation is integrated into the model so that each input image is augmented on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_ds.class_names)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(img_height, img_width, 3)),\n",
    "    data_augmentation,\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "print('Model defined and compiled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "We use early stopping and learning rate reduction callbacks to ensure robust training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "epochs = 30\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")\n",
    "\n",
    "print('Training complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and F1 Score\n",
    "\n",
    "We now evaluate the model on the validation set and compute the weighted F1 score along with a detailed classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect true labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in val_ds:\n",
    "    preds = model.predict(images)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "\n",
    "# Compute weighted F1 score\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "print('Weighted F1 Score:', f1)\n",
    "\n",
    "# Detailed classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_true, y_pred, target_names=train_ds.class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Model to TensorFlow Lite\n",
    "\n",
    "Convert the trained model to a TFLite model for deployment on edge devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Keras model to TFLite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print('TFLite model saved as model.tflite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtesting\n",
    "\n",
    "For backtesting, you can simulate predictions on unseen data or perform cross-validation. The evaluation above on the validation set serves as a backtest. Adjust prediction thresholds or test on a separate hold-out set as needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
